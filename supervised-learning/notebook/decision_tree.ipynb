{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classification with Custom Training Loop\n",
    "\n",
    "In this notebook, we will explore how to build and train a Decision Tree model using the Breast Cancer dataset. We will also define a custom training loop to monitor the model's performance over epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Importing Necessary Libraries\n",
    "\n",
    "We need several libraries for this task:\n",
    "- `tensorflow` for defining the custom model class\n",
    "- `sklearn` for loading the dataset, splitting the data, and calculating metrics\n",
    "- `numpy` for numerical operations\n",
    "- `matplotlib` for plotting the training history\n",
    "- `DecisionTreeClassifier` from `sklearn.tree` for our decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Loading the Breast Cancer Dataset\n",
    "\n",
    "The Breast Cancer dataset is a well-known dataset in machine learning. It contains 569 samples of breast cancer cases, each with 30 features describing the characteristics of the cell nuclei present in the image. The target variable indicates whether the cancer is malignant or benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "x, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Splitting the Data into Training and Testing Sets\n",
    "\n",
    "We split the dataset into training and testing sets to evaluate our model. The training set is used to train the model, while the testing set is used to evaluate its performance on unseen data. We use an 80-20 split for training and testing, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Defining the Custom Decision Tree Model\n",
    "\n",
    "We define a custom model class `MyDecisionTree` by subclassing `tf.keras.Model`. This class will contain:\n",
    "- An instance of `DecisionTreeClassifier` from `sklearn.tree`\n",
    "- A custom training loop to simulate epoch-based training for the decision tree\n",
    "- Methods for predicting, evaluating, and calculating various performance metrics\n",
    "- A method for plotting the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTree(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyDecisionTree, self).__init__()\n",
    "        self.tree = DecisionTreeClassifier(criterion='entropy')\n",
    "        self.history = {\n",
    "            'loss': [], 'accuracy': [], 'precision': [], 'recall': [], 'f1': [],\n",
    "            'val_loss': [], 'val_accuracy': [], 'val_precision': [], 'val_recall': [], 'val_f1': []\n",
    "        }\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.tree.predict(inputs)\n",
    "\n",
    "    def fit(self, x, y, epochs=1, batch_size=32, validation_split=0.2, **kwargs):\n",
    "        \"\"\"\n",
    "        Trains the decision tree model on the input data and tracks performance over epochs.\n",
    "        \n",
    "        This method simulates epoch-based training for decision trees by retraining the model\n",
    "        in each epoch and recording various performance metrics.\n",
    "\n",
    "        Parameters:\n",
    "            x (numpy.ndarray): The feature matrix of the training data.\n",
    "            y (numpy.ndarray): The target values or labels of the training data.\n",
    "            epochs (int): Number of training epochs.\n",
    "            batch_size (int): Size of batches for training (not used in decision trees).\n",
    "            validation_split (float): Fraction of data to use for validation.\n",
    "        \"\"\"\n",
    "        # Split the data into training and validation sets\n",
    "        val_size = int(len(x) * validation_split)\n",
    "        x_train, x_val = x[:-val_size], x[-val_size:]\n",
    "        y_train, y_val = y[:-val_size], y[-val_size:]\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Train the model\n",
    "            self.tree.fit(x_train, y_train)\n",
    "            \n",
    "            # Calculate metrics for training set\n",
    "            train_pred = self.predict(x_train)\n",
    "            train_pred_rounded = train_pred.round()\n",
    "            train_metrics = self.calculate_metrics(y_train, train_pred, train_pred_rounded)\n",
    "            \n",
    "            # Calculate metrics for validation set\n",
    "            val_pred = self.predict(x_val)\n",
    "            val_pred_rounded = val_pred.round()\n",
    "            val_metrics = self.calculate_metrics(y_val, val_pred, val_pred_rounded)\n",
    "            \n",
    "            # Store the metrics\n",
    "            for metric, value in train_metrics.items():\n",
    "                self.history[metric].append(value)\n",
    "            for metric, value in val_metrics.items():\n",
    "                self.history[f'val_{metric}'].append(value)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "            print(f\"Train - loss: {train_metrics['loss']:.4f}, accuracy: {train_metrics['accuracy']:.4f}, \"\n",
    "                  f\"precision: {train_metrics['precision']:.4f}, recall: {train_metrics['recall']:.4f}, \"\n",
    "                  f\"f1: {train_metrics['f1']:.4f}\")\n",
    "            print(f\"Val - loss: {val_metrics['loss']:.4f}, accuracy: {val_metrics['accuracy']:.4f}, \"\n",
    "                  f\"precision: {val_metrics['precision']:.4f}, recall: {val_metrics['recall']:.4f}, \"\n",
    "                  f\"f1: {val_metrics['f1']:.4f}\")\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.tree.predict(x)\n",
    "\n",
    "    def evaluate(self, x, y, **kwargs):\n",
    "        \"\"\"\n",
    "        Evaluates the model's performance on the given data.\n",
    "\n",
    "        Parameters:\n",
    "            x (numpy.ndarray): The feature matrix of the test data.\n",
    "            y (numpy.ndarray): The true target values or labels of the test data.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing various performance metrics.\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(x)\n",
    "        y_pred_rounded = y_pred.round()\n",
    "        return self.calculate_metrics(y, y_pred, y_pred_rounded)\n",
    "\n",
    "    def calculate_metrics(self, y_true, y_pred, y_pred_rounded):\n",
    "        \"\"\"\n",
    "        Calculates various performance metrics for the model.\n",
    "\n",
    "        Parameters:\n",
    "            y_true (numpy.ndarray): The true labels.\n",
    "            y_pred (numpy.ndarray): The predicted probabilities or continuous values.\n",
    "            y_pred_rounded (numpy.ndarray): The rounded predictions (for classification metrics).\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the following metrics:\n",
    "                - loss: Mean Squared Error (MSE)\n",
    "                - accuracy: Proportion of correct predictions\n",
    "                - precision: Ability of the classifier not to label as positive a sample that is negative\n",
    "                - recall: Ability of the classifier to find all positive samples\n",
    "                - f1: Harmonic mean of precision and recall\n",
    "\n",
    "        Notes:\n",
    "            - MSE is used as the loss function, suitable for regression tasks.\n",
    "            - The other metrics (accuracy, precision, recall, f1) are more suitable for classification tasks.\n",
    "            - For multi-class problems, these metrics use a macro-averaging strategy.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'loss': np.mean((y_true - y_pred) ** 2),\n",
    "            'accuracy': accuracy_score(y_true, y_pred_rounded),\n",
    "            'precision': precision_score(y_true, y_pred_rounded, average='macro', zero_division=0),\n",
    "            'recall': recall_score(y_true, y_pred_rounded, average='macro', zero_division=0),\n",
    "            'f1': f1_score(y_true, y_pred_rounded, average='macro', zero_division=0)\n",
    "        }\n",
    "\n",
    "    def plot_training_history(self):\n",
    "        \"\"\"\n",
    "        Plots the training history of the model.\n",
    "        \n",
    "        This method creates five plots:\n",
    "        1. Training and validation loss over epochs\n",
    "        2. Training and validation accuracy over epochs\n",
    "        3. Training and validation precision over epochs\n",
    "        4. Training and validation recall over epochs\n",
    "        5. Training and validation F1-score over epochs\n",
    "        \n",
    "        These plots help visualize the model's performance and identify potential overfitting or underfitting.\n",
    "        \"\"\"\n",
    "        metrics = ['loss', 'accuracy', 'precision', 'recall', 'f1']\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "        axes = axes.flatten()\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axes[i].plot(self.history[metric])\n",
    "            axes[i].plot(self.history[f'val_{metric}'])\n",
    "            axes[i].set_title(f'Model {metric}')\n",
    "            axes[i].set_xlabel('Epoch')\n",
    "            axes[i].set_ylabel(metric.capitalize())\n",
    "            axes[i].legend(['Train', 'Validation'], loc='best')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Creating and Training the Model\n",
    "\n",
    "We create an instance of the `MyDecisionTree` model and train it using the training data. We specify the number of epochs and the validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the modified decision tree model\n",
    "model = MyDecisionTree()\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Evaluating the Model\n",
    "\n",
    "We evaluate the trained model on the testing set to check its performance on unseen data. This helps us understand how well the model generalizes to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics:\n",
      "loss: 0.0000\n",
      "accuracy: 0.9298\n",
      "precision: 0.9335\n",
      "recall: 0.9298\n",
      "f1: 0.9301\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_metrics = model.evaluate(x_test, y_test)\n",
    "print(\"\\nTest Metrics:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Plotting the Training History\n",
    "\n",
    "Finally, we plot the training history to visualize the model's performance over epochs. This includes plots for loss, accuracy, precision, recall, and F1-score for both the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training history\n",
    "model.plot_training_history()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
